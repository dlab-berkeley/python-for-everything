{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel programming with Python's multiprocessing library\n",
    "\n",
    "In this lesson, you will learn how to write programs that perform\n",
    "several tasks in parallel using Python's built-in <a href=\"https://docs.python.org/3/library/multiprocessing.html\" target=\"_blank\">multiprocessing</a> library. You are encouraged to\n",
    "consult the <a href=\"https://docs.python.org/3/library/multiprocessing.html\"\n",
    "target=\"_blank\">documentation</a> to learn more, or to answer any\n",
    "detailed questions as we will only cover a small subset of the\n",
    "library's functionality.\n",
    "\n",
    "This lesson assumes you have completed the \n",
    "[novice python](http://swcarpentry.github.io/python-novice-inflammation/) \n",
    "lessons or have some familiarity with using functions, loops,\n",
    "conditionals, command line argument processing, NumPy, and matplotlib \n",
    "(though don't worry if you don't know NumPy and matplotlib well).\n",
    "\n",
    "> ## Learning Objectives\n",
    "> \n",
    "> - Understand the major parallel programming models\n",
    "> - Learn how to implement simple multiprocessor parallelization\n",
    "> - Evaluate the performance speedup gained from parallelization\n",
    "\n",
    "## Parallel programming models\n",
    "\n",
    "Parallel programming has been important to scientific computing for\n",
    "decades as a way to decrease program run times, making more complex\n",
    "analyses possible (e.g. climate modeling, gene sequencing,\n",
    "pharmaceutical development, aircraft design).\n",
    "\n",
    "One of the motivations for parallel programming has been the\n",
    "diminishing marginal increases in single CPU performance with each new\n",
    "generation of CPU (see <a href=\"http://www.gotw.ca/publications/concurrency-ddj.htm\"\n",
    "target=\"_blank\">The Free Lunch is over</a>).  In response, computer\n",
    "makers have introduced multi-core processors that contain more than\n",
    "one processing core.  It's not uncommon for desktop, laptop, and even\n",
    "tablets and smart phones to have two or more CPU cores.\n",
    "\n",
    "### GPU and heterogeneous computing\n",
    "\n",
    "In addition to multi-core CPUs, Graphics Processing Units (GPU) have\n",
    "become more powerful recently (often having hundreds of parallel\n",
    "execution units). GPUs are increasingly being use not just for drawing\n",
    "graphics to the screen, but for general purpose computation.  GPUs can\n",
    "even be used in conjunction with CPUs to boost parallel computing\n",
    "performance (this is known as heterogeneous computing).  GPUs are best\n",
    "suited to applying the same computation over arrays of data, while\n",
    "CPUs are better suited to algorithms that include conditional branches\n",
    "of execution (e.g. different paths through the code based on if\n",
    "statements). Emerging tools, such as <a href=\"http://en.wikipedia.org/wiki/OpenCL\" target=\"_blank\">OpenCL</a>\n",
    "help coordinate parallel execution across heterogeneous computer\n",
    "platforms that contain differing CPU and GPU resources.\n",
    "\n",
    "### CPU multi-processing / Distributed-memory parallelism\n",
    "\n",
    "Unfortunately, most computer programs cannot take advantage of\n",
    "performance increases offered by GPUs or multi-core CPUs unless we\n",
    "modify these programs.  In this lesson we will develop an example\n",
    "program that uses the Python multiprocessing library to simultaneously\n",
    "execute tasks on a multi-core CPU, decreasing the overall program run\n",
    "time.\n",
    "\n",
    "Multi-processing is one way to execute tasks in parallel on a\n",
    "multi-core CPU, or across multiple computers in a computing cluster.\n",
    "In multi-processing, each task runs in its own process; each program\n",
    "running on your computer is represented by one or more processes. For\n",
    "example, if you are running a web browser, a text editor, and an\n",
    "e-mail client, you are running at least three processes (and likely\n",
    "many more background processes). On modern operating systems, each\n",
    "process gets its own portion of your computer's memory, ensuring that\n",
    "no process can interfere with the execution of another (though tools\n",
    "like <a href=\"http://en.wikipedia.org/wiki/Message_Passing_Interface\"\n",
    "target=\"_blank\">MPI</a> and even Python's multiprocessing library can\n",
    "be used to share data between processes running locally or in\n",
    "distributed computing environments).\n",
    "\n",
    "### CPU multi-threading (shared memory parallelism)\n",
    "\n",
    "Multi-processing is not to be confused with multi-threading, or\n",
    "shared-memory parallelism. In modern operating systems, each process\n",
    "contains one or more threads of execution.  These threads share the\n",
    "same portion of memory assigned to their parent process; each thread\n",
    "can run in parallel if the computer has more than one CPU core. For\n",
    "certain algorithms, multi-threading can be more efficient than\n",
    "multi-processing (though multi-processing solutions such as MPI often\n",
    "scale better to larger problem sizes).  However, multi-threading is\n",
    "more error-prone to program and is generally only done directly by\n",
    "expert systems programmers.  Tools such as <a href=\"http://openmp.org/\" target=\"_blank\">OpenMP</a> should in general\n",
    "be used for multi-threading in scientific computing.\n",
    "\n",
    "## Example application\n",
    "\n",
    "In our example application, we'll show how to parallelize the plotting\n",
    "of randomly generated data using multiple processors.  You can find\n",
    "the complete solution <a href=\"plot_rand_mp.py\"\n",
    "target=\"_blank\">here</a>.  Key portions of the code will be discussed\n",
    "below.  \n",
    "\n",
    "Due to the design of the multiprocessing library, the code portions\n",
    "generally will not work in interactive interpreters such as IPython.\n",
    "Consult the <a\n",
    "href=\"https://docs.python.org/3/library/multiprocessing.html\" target=\"_blank\">documentation</a> for details. To run the example\n",
    "application, download it <a href=\"plot_rand_mp.py\"\n",
    "target=\"_blank\">here</a>, and then, from your command line interface,\n",
    "type:\n",
    "\n",
    "```shell\n",
    "python plot_rand_mp.py --help\n",
    "```\n",
    "\n",
    "for usage instructions. We suggest you create an output directory\n",
    "called \"temp\" to store the plots in (to make deletion easier).\n",
    "\n",
    "### Defining the work to be done\n",
    "\n",
    "Before running code in parallel, we need to define the work to be\n",
    "done. In multiprocessing, this work is defined as a *callable* object,\n",
    "usually a Python function.  Here is the function we'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotData(outputDir, plotNum):\n",
    "    outFilename = \"plot_%d.pdf\" % (plotNum,)\n",
    "    outFilepath = os.path.join(outputDir, outFilename)\n",
    "    \n",
    "    # Plot some random data\n",
    "    # Adapted from: http://matplotlib.org/examples/shapes_and_collections/scatter_demo.html\n",
    "    N = 500\n",
    "    # First we need to re-initialize the random number generator for each worker\n",
    "    # See: https://groups.google.com/forum/#!topic/briansupport/9ErDidIBBFM\n",
    "    np.random.seed( int( time() ) + plotNum )\n",
    "    x = np.random.rand(N)\n",
    "    y = np.random.rand(N)\n",
    "    area = np.pi * (15 * np.random.rand(N))**2 # 0 to 15 point radiuses\n",
    "\n",
    "    print(\"\\tMaking plot %d\" % (plotNum,) )\n",
    "    plt.scatter(x, y, s=area, alpha=0.5)\n",
    "    plt.savefig(outFilepath)\n",
    "    # Clear figure so that the next plot this worker makes will not contain\n",
    "    # data from previous plots\n",
    "    plt.clf() \n",
    "    \n",
    "    return (plotNum, outFilepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes as input the path of the output directory to which\n",
    "plots should be saved, and the unique identifier of the plot we are\n",
    "creating; the function returns the path of the PDF file to which the\n",
    "plotted data were written, as well as the plot identifier.  The reason\n",
    "for returning the plot identifier will be described below.\n",
    "\n",
    "Don't worry if you are not familiar with NumPy or matplotlib.  All\n",
    "we're doing here is making a scatter plot of random data.  As is, this\n",
    "is not a very useful task, however it could easily be extended to plot\n",
    "actual data.\n",
    "\n",
    "**The key thing to note about this function is that when executing code\n",
    "in parallel environments, weird behavior can result unless special\n",
    "care is taken in your code** (even when doing multi-processing\n",
    "programming where each process has its own memory space).  In this\n",
    "case, there are two special things we must do.\n",
    "\n",
    "First, we must force NumPy's random number generator to\n",
    "re-initialize for each call of the parallel function, this is\n",
    "accomplished by:\n",
    "\n",
    "```python\n",
    "np.random.seed( int( time() ) + plotNum )\n",
    "```\n",
    "\n",
    "Where we use the current system time and the plot identifier as a *seed*\n",
    "for the random number generator.  If we don't do this, each worker\n",
    "process will use the same random number generator as it makes the\n",
    "plots it is responsible for.  Thus, all plots made by Worker 1 would\n",
    "contain the same sequence of \"random\" data.\n",
    "\n",
    "Second, we need to tell matplotlib to clear the current figure\n",
    "context after each plot is generated:\n",
    "\n",
    "```python\n",
    "plt.clf()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, each plot made by Worker 1 would contain the data from all\n",
    "previous plots created by Worker 1.\n",
    "\n",
    "### Creating a pool of workers\n",
    "\n",
    "Now that we have defined the work to be done, we can write the code to\n",
    "execute in tasks in parallel.  There are several ways to use Python's\n",
    "multiprocessing library to execute tasks in parallel.  In this lesson\n",
    "we'll use a <a href=\"https://docs.python.org/3/library/multiprocessing.html#using-a-pool-of-workers\"\n",
    "target=\"_blank\">pool of worker processes</a>.\n",
    "\n",
    "Assuming we import the multiprocessing library as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can create a pool by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool( args.numProcessors )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, we're passing in the number of processors to use via\n",
    "an optional command line argument called `numProcessors`.  If the user\n",
    "doesn't specify the number of processors on the command line, the\n",
    "default value is determined using the cpu_count() method of\n",
    "multiprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We're using the <a href=\"https://docs.python.org/3/library/argparse.html\"\n",
    "> target=\"_blank\">argparse</a> library, a standard part of Python 2.7\n",
    "> and later, to manage command line arguments.\n",
    "\n",
    "### Build a list of tasks\n",
    "\n",
    "Okay.  We have a pool of workers, and a we have a description of how\n",
    "workers should perform a task in the abstract.  Before we can run any\n",
    "tasks we need to make a list of specific tasks to be performed\n",
    "(i.e. plots to be created).  We do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tasks = []\n",
    "plotNum = 0\n",
    "while plotNum < args.numPlots:\n",
    "    plotNum += 1\n",
    "    tasks.append( (args.outputDir, plotNum, ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each task is simply a tuple of the path where plot PDF files should be\n",
    "saved and as well as the current plot identifier.  We store these\n",
    "tuples in a list called `tasks`, thus our tasks are described as a\n",
    "list of tuples.\n",
    "\n",
    "### Run tasks in parallel\n",
    "\n",
    "To run our tasks in parallel across all workers, we use the\n",
    "[`apply_async`](https://docs.python.org/2.7/library/multiprocessing.html#multiprocessing.pool.multiprocessing.Pool.apply_async)\n",
    "method of the worker pool class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [pool.apply_async( plotData, t ) for t in tasks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we call `apply_async` from a list comprehension for convenience, but\n",
    "you could also iterate over the tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for t in tasks:\n",
    "    results.append( pool.apply_async( plotData, t) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In either case, we pass our `plotData` function as well as the\n",
    "individual task tuple to `plot_async`.  The multiprocessing library\n",
    "will take care of dispatching our tasks to each worker so that the\n",
    "tasks can be performed in parallel.\n",
    "\n",
    "### Getting results\n",
    "\n",
    "Once we've dispatched all tasks we'll want to get the results returned\n",
    "by each task and do something with those results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    (plotNum, plotFilename) = result.get()\n",
    "    print(\"Result: plot %d written to %s\" % (plotNum, plotFilename) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the results for each task by calling the `get` method on that\n",
    "task's result object.  Calls to `get` will wait until there are\n",
    "results available (this is called \"blocking\").  You can optionally set\n",
    "a timeout after which an exception will be raised if a result is not\n",
    "returned (this is useful if your task involves network activity).\n",
    "\n",
    "Remember that our task function `plotData` returns a tuple of the plot\n",
    "identifier as well as the filename of the plot generated.  You might\n",
    "be asking yourself why would we need to return the plot identifier\n",
    "when the plot identifier was passed into the worker function, and did\n",
    "not change in the worker function.  This is necessary because the\n",
    "worker pool makes no guarantee that workers will complete their tasks\n",
    "in any particular order.  Indeed, in a more realistic application, each\n",
    "tasks' workload may vary, so there is no way to know how long each task\n",
    "will take to complete.\n",
    "\n",
    "In our example we simply print out the plot identifier and the name of\n",
    "file produced.  If the worker function were performing a numerical\n",
    "computation, we could instead do something with that result, such as\n",
    "adding the result to the results obtained from other tasks.\n",
    "\n",
    "## Typical output\n",
    "\n",
    "Here is the output that our example program should produce:\n",
    "\n",
    "```\n",
    "$ ./plot_rand_mp.py -o temp -n 4\n",
    "Making 4 plots of random data using 8 processors...\n",
    "       Making plot 1\n",
    "       Making plot 2\n",
    "       Making plot 3\n",
    "       Making plot 4\n",
    "Result: plot 1 written to temp/plot_1.pdf\n",
    "Result: plot 2 written to temp/plot_2.pdf\n",
    "Result: plot 3 written to temp/plot_3.pdf\n",
    "Result: plot 4 written to temp/plot_4.pdf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speedup\n",
    "\n",
    "Whenever we decide to parallelize a task, it is important to evaluate\n",
    "the runtime savings and efficiency of our parallel program.  <a\n",
    "href=\"http://en.wikipedia.org/wiki/Speedup\" target=\"_blank\">Speedup\n",
    "and efficiency</a> are common ways of doing this.\n",
    "\n",
    "> Before decided parallelize or otherwise optimize a program, you\n",
    "> should first use a <a href=\"http://en.wikipedia.org/wiki/Profiling_(computer_programming)\"\n",
    "> target=\"_blank\">profiler</a> to identify what proportion of runtime\n",
    "> your program is spending in each function or component. This will\n",
    "> help you to prioritize optimization or parallelization to maximize\n",
    "> runtime reductions.\n",
    "\n",
    "Speedup (Sp) is defined as the ratio of runtime for a sequential\n",
    "algorithm (T1) to runtime for a parallel algorithm with *p* processors\n",
    "(Tp). That is, Sp = T1 / Tp. Ideal speedup results when Sp = p.\n",
    "Speedup is formally derived from <a href=\"http://en.wikipedia.org/wiki/Amdahl's_law\"\n",
    "target=\"_blank\">Amdahl's law</a>, which considers the portion of a\n",
    "program that is serial vs. the portion that is parallel when\n",
    "calculating speedup.\n",
    "\n",
    "Efficiency (Ep) is defined as the ratio of speedup for p processors (Sp) to\n",
    "the number of processors p, or Ep = Sp / p.\n",
    "\n",
    "Below is a graph comparing the speedup and efficiency that resulted when\n",
    "running the example program to create 64 plots using a range of\n",
    "processors on computer with a 4-core processor (each data point\n",
    "represents the average of three runs).\n",
    "![Speedup plot](intermediate-fig/speedup.png \"Plot of speedup and efficiency of example parallel program\")\n",
    "\n",
    "> Note that the comparison here is not quite fair because a sequential\n",
    "> version of the program was not written.  The runtime for the\n",
    "> sequential version were approximated by running the parallel version\n",
    "> using a single processor.  The single processor runtime was likely\n",
    "> longer than that of a sequential version of the same program due to\n",
    "> the overhead needed to create the worker pool and dispatch a single\n",
    "> task to a worker.  Thus these results slightly overstate the\n",
    "> parallel speedup and efficiency.\n",
    "\n",
    "First note that the slope of the speedup curve is low, and grows\n",
    "farther away from the ideal speedup line as the number of processors\n",
    "increases.  Some divergence between actual and ideal speedup is\n",
    "typical.  However our example program isn't strictly computational and\n",
    "involves input/output (I/O) to the filesystem (i.e. writing the plot).\n",
    "I/O-bound tasks do not typically parallelize well because I/O\n",
    "resources (e.g. disks, network, memory) are shared across processors,\n",
    "and because I/O operations, especially to disk, usually take orders of\n",
    "magnitude more time to complete than computational operations.\n",
    "However, even I/O-bound tasks can see moderate speedup due to the\n",
    "effects of \"pipelining\" (see <a href=\"http://en.wikipedia.org/wiki/Pipeline_(computing)\"\n",
    "target=\"_blank\">here</a>).\n",
    "\n",
    "Efficiency, which ranges from 0 to 1, is a bit easier to interpret\n",
    "than speedup. With two processors, efficiency was over 90% (i.e. our\n",
    "two workers were 90% utilized, doing useful work far more than they\n",
    "were waiting for I/O). As processors were added to the worker pool,\n",
    "the efficiency dropped, which is expected for a task dependent on I/O.\n",
    "However, the speedup continued increasing up to and including eight\n",
    "processors; that is, runtimes continued to drop until we added more\n",
    "than eight workers.  Thus, even though efficiency was decreasing, we\n",
    "were still able to save time by adding more workers, up to a point.\n",
    "Efficiency is especially important in enterprise computing\n",
    "environments, where concerns like providing equitable access shared\n",
    "resources and reducing energy consumption may dictate the use of fewer\n",
    "processors to maintain higher processor utilization.\n",
    "\n",
    "> Despite our computer having only 4-cores, why did runtime continue\n",
    "> to decrease between four and eight processors?  This was in part\n",
    "> because the computer we ran the tests on had a feature call\n",
    "> \"HyperThreading.\"  HyperThreading is the marketing name of a\n",
    "> technology that enables each physical core of a CPU to appear as two\n",
    "> virtual cores to your operating system.  These virtual cores can\n",
    "> improve performance, but are rarely as effective as additional\n",
    "> physical cores.\n",
    "\n",
    "## Communication between the processes\n",
    "\n",
    "Running a computation in multiple processes requires some\n",
    "communication between these processes. One of the nice aspects of\n",
    "multiprocessing in Python is that most of the time you do not need to\n",
    "know *how* this communication is handled: it just works. However, it\n",
    "is useful to understand the basics of this mechanism in order to\n",
    "figure out how to solve two kinds of problems: unexpected errors, and\n",
    "bad performance.\n",
    "\n",
    "Communication between processes takes the form of streams of bytes\n",
    "that travel through specific communication channels. To send an object\n",
    "from one process to another, Python has to convert it to a stream of\n",
    "bytes, and assemble the object back at the receiving end.  Python's\n",
    "mechanism for doing these conversions was originally designed for\n",
    "storing objects in files and is implemented in the <a href=\"https://docs.python.org/2.7/library/pickle.html\"\n",
    "target=\"_blank\">pickle</a> module. Every argument that is passed to a\n",
    "Python function running in another process is pickled and then\n",
    "unpickled. The result of the function undergoes the same process on\n",
    "its way back.\n",
    "\n",
    "There are two things you need to know about pickle in the context of\n",
    "multiprocessing. First, most objects can be pickled but some cannot.\n",
    "Second, pickling and unpickling take time and can sometimes add\n",
    "considerable overhead to your multiprocessing.\n",
    "\n",
    "The objects that cannot be pickled come in two varieties: those for\n",
    "which pickling does not make sense, and those for which it has simply\n",
    "not been implemented. A good example for the first category is file\n",
    "objects. The second category contains mainly object types defined in\n",
    "extension modules whose authors didn't implement pickling. If you use\n",
    "an old release of NumPy, you may discover that its array-aware\n",
    "functions are not picklable, making it impossible to use such a\n",
    "function directly as a task in multiprocessing. For Python's built-in\n",
    "objects, there is one important restriction that is due to the\n",
    "implementation details of pickle: functions and classes can only be\n",
    "pickled if they are defined at the top level of a module. This means,\n",
    "for example, that if you define a function inside another function,\n",
    "you cannot pickle it and thus not pass it to a multiprocessing task.\n",
    "\n",
    "The performance implications of pickling are rather obvious: you\n",
    "should try to pass as few arguments as possible to your tasks, and\n",
    "make sure you pass no more data than you really need to.  For example,\n",
    "rather than passing a huge list and the index of the item that your\n",
    "taks is supposed to process, you should pass only that item.\n",
    "\n",
    "> ## Challenge\n",
    "> \n",
    "> Run the <a href=\"plot_rand_mp.py\" target=\"_blank\">example\n",
    "> application</a> on your computer several times.  Each time, vary the\n",
    "> number of processors to use and note how the computation efficiency\n",
    "> varies.  You can use the Unix `time` program to measure execution\n",
    "> times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points\n",
    "\n",
    "- CPU multi-processing is a parallel programming technique that can\n",
    "  harness the power of modern computers to help you perform more\n",
    "  analyses more quickly.\n",
    "\n",
    "- The Python multiprocessing library allows you to create a pool of\n",
    "  workers to carry out tasks in parallel\n",
    "\n",
    "- Tasks are easy to describe using Python functions\n",
    "\n",
    "- Care needs to be taken when executing code in parallel environments\n",
    "  to avoid strange program behavior and wrong computations\n",
    "\n",
    "- You can combine results from individual tasks allowing each worker\n",
    "  to share in the computational load\n",
    "\n",
    "- It is important to use profiling before optimizing computer programs\n",
    "\n",
    "- Metrics such as speedup and efficiency aid in evaluating the\n",
    "  performance and utility of parallel programs\n",
    "\n",
    "## Next steps\n",
    "\n",
    "Using the <a href=\"plot_rand_mp.py\" target=\"_blank\">example\n",
    "program</a> as a starting point, you should be able to create your own\n",
    "parallel program that will save you time and help you to get more\n",
    "performance out of your existing computer hardware (which you've\n",
    "already paid for!)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
